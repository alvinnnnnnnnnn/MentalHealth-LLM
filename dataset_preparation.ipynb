{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import re  # For regular expressions (if needed)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chunk_pdf_by_sections(pdf_path, section_markers=None):  # section_markers can be regex or list of headings\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "\n",
    "    chunks = []\n",
    "\n",
    "    if section_markers:  # Automatic section detection\n",
    "        if isinstance(section_markers, list): # List of headings\n",
    "            for marker in section_markers:\n",
    "                # Use regex to find start and end of section\n",
    "                matches = re.finditer(rf\"(^{marker}$)([\\s\\S]*?)(?=(^{section_markers[section_markers.index(marker) + 1]}$)|$)\", text, re.MULTILINE) if section_markers.index(marker) < len(section_markers) - 1 else re.finditer(rf\"(^{marker}$)([\\s\\S]*?)$\", text, re.MULTILINE)\n",
    "                for match in matches:\n",
    "                    chunks.append(match.group(2).strip())\n",
    "        elif isinstance(section_markers, str): # Regex for section start\n",
    "             matches = re.finditer(section_markers, text, re.MULTILINE)\n",
    "             for match in matches:\n",
    "                start = match.start()\n",
    "                end = text.find(section_markers, start + 1) if text.find(section_markers, start + 1) != -1 else len(text)\n",
    "                chunks.append(text[start:end].strip())\n",
    "\n",
    "    else:  # Manual annotation (example)\n",
    "        # (Implementation for reading section boundaries from a separate file or markers in the text)\n",
    "        # ... (Add your logic here) ...\n",
    "        pass # replace with your logic\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Example usage (automatic - list of headings):\n",
    "section_headings = [\"Introduction\", \"Symptoms\", \"Treatment\", \"Prevention\"]  # Your actual section headings\n",
    "chunks = chunk_pdf_by_sections(\"mental_health.pdf\", section_headings)\n",
    "\n",
    "# Example usage (automatic - regex):\n",
    "section_regex = r\"^##\\s*(.+)$\"  # Regex to find section starts (e.g. Markdown headings)\n",
    "chunks = chunk_pdf_by_sections(\"mental_health.pdf\", section_regex)\n",
    "\n",
    "# Example usage (manual annotation):\n",
    "# chunks = chunk_pdf_by_sections(\"mental_health.pdf\") # You'd need to implement the manual parsing\n",
    "\n",
    "with open(\"my_dataset.txt\", \"w\") as outfile:\n",
    "    for chunk in chunks:\n",
    "        outfile.write(chunk + \"\\n\")  # Each chunk on a new line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your full dataset\n",
    "dataset = load_dataset(\"text\", data_files={\"full\": \"your_dataset.txt\"})\n",
    "\n",
    "# Split into train and (val+test)\n",
    "train_dataset, eval_test_dataset = train_test_split(dataset[\"full\"], test_size=0.3, random_state=42) # Adjust test_size as needed\n",
    "\n",
    "# Split (val+test) into validation and test\n",
    "eval_dataset, test_dataset = train_test_split(eval_test_dataset, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert to Hugging Face datasets\n",
    "train_dataset = load_dataset(\"text\", data_files={\"train\": train_dataset})\n",
    "eval_dataset = load_dataset(\"text\", data_files={\"eval\": eval_dataset})\n",
    "test_dataset = load_dataset(\"text\", data_files={\"test\": test_dataset})\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True, remove_columns=[\"train\"])\n",
    "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True, remove_columns=[\"eval\"])\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True, remove_columns=[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = pd.read_csv(\"dataset/q&a.csv\", encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>bot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm feeling really down lately, is there a dif...</td>\n",
       "      <td>Yes, there is a difference. Sadness is a norma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are some of the signs and symptoms of dep...</td>\n",
       "      <td>Some common signs and symptoms include: persis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I've heard there are different types of depres...</td>\n",
       "      <td>Yes, there are several types of depressive dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My friend is going through a tough time and se...</td>\n",
       "      <td>The most important thing is to encourage your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is depression more common in certain groups of...</td>\n",
       "      <td>Depression can affect anyone, but it is more c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Substance abuse is a concern for me. How can I...</td>\n",
       "      <td>It's commendable that you're seeking support. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>How does the Singaporean government plan to im...</td>\n",
       "      <td>The Singaporean government has launched the Na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Where can I find reliable information about me...</td>\n",
       "      <td>You can find reliable information on the Minis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>How can I help to reduce the stigma surroundin...</td>\n",
       "      <td>By having open and honest conversations about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>How does the Singapore government plan to make...</td>\n",
       "      <td>The Singapore government plans to make mental ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  user  \\\n",
       "0    I'm feeling really down lately, is there a dif...   \n",
       "1    What are some of the signs and symptoms of dep...   \n",
       "2    I've heard there are different types of depres...   \n",
       "3    My friend is going through a tough time and se...   \n",
       "4    Is depression more common in certain groups of...   \n",
       "..                                                 ...   \n",
       "115  Substance abuse is a concern for me. How can I...   \n",
       "116  How does the Singaporean government plan to im...   \n",
       "117  Where can I find reliable information about me...   \n",
       "118  How can I help to reduce the stigma surroundin...   \n",
       "119  How does the Singapore government plan to make...   \n",
       "\n",
       "                                                   bot  \n",
       "0    Yes, there is a difference. Sadness is a norma...  \n",
       "1    Some common signs and symptoms include: persis...  \n",
       "2    Yes, there are several types of depressive dis...  \n",
       "3    The most important thing is to encourage your ...  \n",
       "4    Depression can affect anyone, but it is more c...  \n",
       "..                                                 ...  \n",
       "115  It's commendable that you're seeking support. ...  \n",
       "116  The Singaporean government has launched the Na...  \n",
       "117  You can find reliable information on the Minis...  \n",
       "118  By having open and honest conversations about ...  \n",
       "119  The Singapore government plans to make mental ...  \n",
       "\n",
       "[120 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset/dataset.csv\")  # Replace \"conversations.csv\" with your file name\n",
    "dataframe = pd.concat([df, qa], ignore_index=True)\n",
    "dataframe = dataframe.dropna(axis=1, how='all')\n",
    "\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file removed\n",
      "file removed\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "text_data = []\n",
    "\n",
    "# Define file paths\n",
    "train_file = \"dataset/train.txt\"\n",
    "val_file = \"dataset/val.txt\"\n",
    "\n",
    "# Check if files exist and delete them\n",
    "for file in [train_file, val_file]:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        print(\"file removed\")\n",
    "\n",
    "# Ensure dataset directory exists\n",
    "os.makedirs(\"dataset\", exist_ok=True)\n",
    "\n",
    "for i in range(0, len(dataframe)):\n",
    "    user_utterance = dataframe['user'][i] # Access user utterance using column name\n",
    "    bot_utterance = dataframe['bot'][i] # Access bot utterance using column name\n",
    "\n",
    "    # Handle missing values (if any)\n",
    "    if pd.isna(user_utterance):\n",
    "        user_utterance = \"User: \"  # Or some other placeholder\n",
    "    if pd.isna(bot_utterance):\n",
    "        bot_utterance = \"Bot: I don't know.\"  # Or a default response\n",
    "\n",
    "    text_data.append(f\"User: {user_utterance}\")\n",
    "    text_data.append(f\"Bot: {bot_utterance}\")\n",
    "\n",
    "# 3. Split into training and validation sets\n",
    "train_data = text_data[:int(len(text_data)*0.8)]  # 80% for training\n",
    "val_data = text_data[int(len(text_data)*0.8):]  # 20% for validation\n",
    "\n",
    "# 4. Save to text files (train.txt and val.txt)\n",
    "with open(\"dataset/train.txt\", \"w\", encoding=\"utf-8\") as f: # Add encoding for special characters\n",
    "    for line in train_data:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "with open(\"dataset/val.txt\", \"w\", encoding=\"utf-8\") as f: # Add encoding for special characters\n",
    "    for line in val_data:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "# ... (rest of your fine-tuning code using train.txt and val.txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
